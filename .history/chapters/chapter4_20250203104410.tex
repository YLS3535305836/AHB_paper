\chapter{}
针对模型在复杂现实的泛化能力不足和数据多样性匮乏这两个问题，本章创新性地提出了一种毫米波雷达点云姿态识别的数据增强方法——$PointCloud PoseFusion$(PCPF)。该方法主要通过将特定的关键动作的点云数据定性提取并拼接到不同非关键动作点云场景中，以克服复杂场景点云数据难采集的问题，还可以增加点云数据多样性，以提升模型在复杂现实场景中的泛化能力。


\section{问题分析}
\section{PCPF毫米波雷达点云姿态识别数据增强方案}

\subsection{数据预处理}
%主要是数据预处理部分的公式推导，augment数据的公式
\subsection{PCPF数据增强算法}
%把python代码写成latex算法的格式



\section{实验设计和结果分析}
\subsection{实验评估指标}
\subsection{实验环境配置与训练参数设置}
\subsection{数据可视化分析}
\subsection{融合率与分段帧长对模型性能的影响}
% fusion_ratio: 20/30/40/50
% frame_len: 30/35/40/45/50/55/60
\subsection{采样方式对模型性能的影响}
%重复采样 vs 普通采样


\subsection{对比实验}
% 数据增强前后对比
%前后模型的评估指标对比(表格)
\begin{table}[h]
    \centering
    \caption{模型数据增强前后评估指标对比}
    \begin{tabular}{|c|c|c|c|c|}
        \hline
        \textbf{模型} & \textbf{准确率前} & \textbf{准确率后} & \textbf{精确率前} & \textbf{精确率后} \\ \hline
        PointNet & 59.1\% & 64.1\% & 55.0\% & 60.0\% \\ \hline
        PointNet++ & 88.6\% & 90.6\% & 87.0\% & 89.0\% \\ \hline
        PointCNN & 88.4\% & 89.4\% & 86.5\% & 87.5\% \\ \hline
        SpiderCNN & 90.6\% & 92.6\% & 89.0\% & 91.0\% \\ \hline
        DGCNN & 93.1\% & 94.1\% & 92.0\% & 93.0\% \\ \hline
        RsNet & 92.1\% & 93.1\% & 91.0\% & 92.0\% \\ \hline
        MR-PPFN PointNet-BiLSTM & 88.6\% & 89.6\% & 87.0\% & 88.0\% \\ \hline
        MR-PPFN PointNet++-BiLSTM & 88.6\% & 90.6\% & 87.0\% & 89.0\% \\ \hline
        MR-PPFN PointCNN-BiLSTM & 88.4\% & 89.4\% & 86.5\% & 87.5\% \\ \hline
        MR-PPFN SpiderCNN-BiLSTM & 90.6\% & 92.6\% & 89.0\% & 91.0\% \\ \hline
        MR-PPFN DGCNN-BiLSTM & 92.3\% & 93.3\% & 91.5\% & 92.5\% \\ \hline
        MR-PPFN RsNet-BiLSTM & 92.3\% & 93.3\% & 91.5\% & 92.5\% \\ \hline
    \end{tabular}
    \label{tab:model-comparison}
\end{table}
 
%前后的模型的准确率的条状对比图
%前后数据量的对比(条状图)


